{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: Plan of whole pipeline from Ref-genome/vcf-file/TSS-file/ to basenji-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "ask Ziga about: vcf-gtex-gile\n",
    "run libs through with him\n",
    "\n",
    "add warning if Ref-Base is not base in VCF -> probl. due to shifted positions\n",
    "\n",
    "Classes: \n",
    "\n",
    "    [later: PipelineConfigurator: takes Gene-IDs  and sample-IDs from user, writes into output file\n",
    "            Calls all others, needs therefor all files. Makes sure that Intervall-Translator and model are compatible\n",
    "    ]\n",
    "    TODO:\n",
    "    Basenji-call with input\n",
    "    ResultWriter: puts results in Xarray with dimensions Gene/Sample/Outputvalues, stores it to disk\n",
    "    \n",
    "    Now: REPDataloader which reads in TSS, passes intervals to vcfFastaExtractor:\n",
    "    \n",
    "    TSS: not dataloader, is small...\n",
    "    but: IntervalCalculator: do...\n",
    "    \n",
    "    vcfFastaExtractor\n",
    "    random fasta access: pyfaidx\n",
    "    random vcf-access: pyVCF\n",
    "    \n",
    "    output: one-hot-encoded seq with annotations: geneID, sampleID, posiRefStart , ALLELE (0 or 1)\n",
    "    \n",
    "Input-files:\n",
    "\n",
    "   RefGenome in fasta: https://raw.githubusercontent.com/kipoi/kipoiseq/master/tests/data/hg38_chr22_32000000_32300000.fa\n",
    "   \n",
    "   (not used: intervalls-example: https://raw.githubusercontent.com/kipoi/kipoiseq/master/tests/data/intervals_51bp.tsv)\n",
    "   \n",
    "   CAGE TSS `/s/project/avsec/ExPecto/resources/geneanno.csv`\n",
    "   has:\n",
    "    lincRNA\n",
    "    lincRNA\n",
    "    protein_coding\n",
    "    rRNA\n",
    "   -> which to use?\n",
    "   \n",
    "   GTEx-vcf? maybe from /s/project/gtex-processed/vcf/GTEx_Analysis_20150112_WholeGenomeSeq_148Indiv_GATK_HaplotypeCaller.vcf.gz\n",
    "   \n",
    "   RefGenome: /s/genomes/human/hg38$ \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "------\n",
    "   Use loading-param from:\n",
    "   https://github.com/kipoi/kipoi/blob/master/kipoi/data.py\n",
    "          dl = DataLoader(self, batch_size=1,\n",
    "                        collate_fn=numpy_collate_concat,    <---\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "drop_last=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Todo next:\n",
    "    fix allelic-extractor-error: SingleSeqVCFSeqExtractor freezes already with actual variant...\n",
    "    check/load Zarrwriter file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing aroudn with fasta/vcf/tss-libs and fileformats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyfaidx in /data/nasif12/modules_if12/SL7/i12g/anaconda/3-5.0.1/lib/python3.6/site-packages (0.5.4.2)\n",
      "Requirement already satisfied: setuptools>=0.7 in /data/nasif12/modules_if12/SL7/i12g/anaconda/3-5.0.1/lib/python3.6/site-packages (from pyfaidx) (39.1.0)\n",
      "Requirement already satisfied: six in /data/nasif12/modules_if12/SL7/i12g/anaconda/3-5.0.1/lib/python3.6/site-packages (from pyfaidx) (1.12.0)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " !pip install pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "refGenome = Fasta('/s/genomes/human/hg38/hg38.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ">chr1:40001-40100\n",
       "gcctcatggaggggatcagctgcgaggagctaagagccccctccagtcgatgctcaccaggaagctgaggtcttgtgtccagcaccctgcatagaactga"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refGenome[\"chr1\"][40000:40100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "\n",
    "vcf_reader = vcf.Reader(filename='/s/project/gtex-processed/vcf/GTEx_Analysis_20150112_WholeGenomeSeq_148Indiv_GATK_HaplotypeCaller.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example for calling\n",
    "for record in vcf_reader.fetch('20', 1110695, 1110780):  \n",
    "    print(record.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy troubles: in terminal, in RIGHT env: conda install numpy==1.15\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,symbol,seqnames,strand,TSS,CAGE_representative_TSS,type\n",
      "ENSG00000000003,TSPAN6,chrX,-,99894988,99891748,protein_coding\n",
      "ENSG00000000005,TNMD,chrX,+,99839799,99839933,protein_coding\n",
      "ENSG00000000419,DPM1,chr20,-,49575092,49575069,protein_coding\n",
      "ENSG00000000457,SCYL3,chr1,-,169863408,169863037,protein_coding\n",
      "ENSG00000000460,C1orf112,chr1,+,169631245,169764186,protein_coding\n",
      "ENSG00000000938,FGR,chr1,-,27961788,27961654,protein_coding\n",
      "ENSG00000000971,CFH,chr1,+,196621008,196621174,protein_coding\n",
      "ENSG00000001036,FUCA2,chr6,-,143832827,143832857,protein_coding\n",
      "ENSG00000001084,GCLC,chr6,-,53481768,53409899,protein_coding\n"
     ]
    }
   ],
   "source": [
    "!head /s/project/avsec/ExPecto/resources/geneanno.csv\n",
    "\n",
    "import pandas as pd\n",
    "testCSV=pd.read_csv(\"/s/project/avsec/ExPecto/resources/geneanno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper classes for TSS-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,5,6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1,0,1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Interval(object):\n",
    "    \"\"\"\n",
    "    stores window-range-info\n",
    "    as usual in python, an [ ) interval\"\"\"\n",
    "    def __init__(self, n_up,n_down,anchor=None):\n",
    "        if n_up==n_down:\n",
    "            raise AttributeError(\"An interval without elements is not supported. Your upper and lower bound(exclusive) are the same.\")\n",
    "            \n",
    "        \n",
    "        self.lower=n_up\n",
    "        self.upper=n_down\n",
    "        self.anchor=anchor\n",
    "        if anchor is None:\n",
    "            self.anchor=int((self.lower+self.upper)/2)\n",
    "    def setAnchor(self,newAnchor):\n",
    "        self.lower=newAnchor-(self.anchor-self.lower)\n",
    "        self.upper=newAnchor+(self.upper-self.anchor)\n",
    "        self.anchor=newAnchor\n",
    "    def __str__(self):\n",
    "        return \"[{},{},{})\".format(self.lower,self.anchor,self.upper)\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    def __len__(self):\n",
    "        return self.upper-self.lower\n",
    "        \n",
    "test=Interval(4,6)\n",
    "print(test)\n",
    "test.setAnchor(0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'CC']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VcfFastaDummy(object):\n",
    "    def __init__(self,a,b):\n",
    "        pass\n",
    "    def extract(self,interval,sample): \n",
    "        allele1=\"A\"*len(interval)\n",
    "        allele2=\"C\"*len(interval)\n",
    "        return [allele1,allele2]\n",
    "    \n",
    "test=VcfFastaDummy(\"a\",\"b\")\n",
    "test.extract(Interval(3,5),\"testSample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.6.7\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/modules/i12g/anaconda/3-5.0.1/envs/rep\n",
      "\n",
      "  added / updated specs: \n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cudnn-7.3.1                |        cuda9.0_0       331.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    cffi:        1.11.5-py36he75722e_1\n",
      "    cudatoolkit: 9.0-h13b8566_0       \n",
      "    cudnn:       7.3.1-cuda9.0_0      \n",
      "    nccl:        1.3.5-cuda9.0_0      \n",
      "    ninja:       1.8.2-py36h6bb024c_1 \n",
      "    pycparser:   2.19-py36_0          \n",
      "    pytorch:     0.4.1-py36ha74772b_0 \n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "cudnn-7.3.1          | 331.3 MB  | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install pytorch -y # for dataloader/set-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        from kipoiseq.transforms import ReorderedOneHot\n",
    "        testTransform=ReorderedOneHot()\n",
    "        testTransform(\"ACCC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSSloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "#formerly \"repDataloader\"\n",
    "class RepDataset(Dataset):\n",
    "    from pybedtools import Interval\n",
    "    \n",
    "    def __init__(self,vcfFile,refGenFasta,tssFile,n_upstream,n_downstream,sample_ids):\n",
    "        \"\"\"set instance-vars, read TSS completely, load (dummy) VCFfastaExtractor\"\"\"\n",
    "\n",
    "        import pandas as pd\n",
    "\n",
    "        from kipoiseq.transforms import ReorderedOneHot\n",
    "        self.transform=ReorderedOneHot()\n",
    "        \n",
    "        \n",
    "        self.vcfFile=vcfFile\n",
    "        self.refGenFasta=refGenFasta\n",
    "        self.varExtractor=VcfFastaDummy(vcfFile,refGenFasta)\n",
    "        \n",
    "        self.sampleIDs=sample_ids\n",
    "        self.interval=Interval(n_upstream,n_downstream)\n",
    "        \n",
    "        #TODO use only prot-coding? Separate file or bound to schema of example file?\n",
    "        self.tssCollection=pd.read_csv(tssFile) # needs field \"TSS\" with RegGen position and \"strand\" with \"+\" or \"-\"\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampleIDs)*len(self.tssCollection)\n",
    "    def __getitem__(self,idx):\n",
    "        import numpy as np\n",
    "        \"\"\"transform idx to sample- and tss-id, then get both alleles from extractor\"\"\"\n",
    "        sampleIdx=int(idx/len(self.tssCollection))\n",
    "        tssIdx=int(idx%len(self.tssCollection))\n",
    "        \n",
    "        \n",
    "        chromo=self.tssCollection.loc[tssIdx,\"seqnames\"]\n",
    "        strand=self.tssCollection.loc[tssIdx,\"strand\"]\n",
    "        tssStart=self.tssCollection.loc[tssIdx,\"TSS\"]\n",
    "        \n",
    "        genomic_interval=self.getGenomicInterval(chromo,tssStart,strand)  \n",
    "        \n",
    "        alleles= self.varExtractor.extract(genomic_interval,self.sampleIDs[sampleIdx]) #strand-info where?\n",
    "        \n",
    "        #formatting output\n",
    "        gene_id=self.tssCollection.loc[tssIdx,\"id\"]\n",
    "        sample_id=self.sampleIDs[sampleIdx]\n",
    "        returnBatch={}\n",
    "        returnBatch[\"inputs\"]=[self.transform(alleles[0]),self.transform(alleles[1])]\n",
    "        #need np.array-conversion, or it will concat on other dimension for batchsize>1\n",
    "        returnBatch[\"metadata\"]={\"gene_id\":np.array([gene_id]*2),\"sample_id\":np.array([sample_id]*2),\"allele_id\":np.array([0,1])} \n",
    "        return returnBatch\n",
    "    \n",
    "    def getGenomicInterval(self,chromosome,chromoAnchor,strand):\n",
    "        \"\"\"converts internal interval to bedInterval as used in extractor\"\"\"\n",
    "        from pybedtools import Interval\n",
    "        self.interval.setAnchor(chromoAnchor)\n",
    "        return Interval(chromosome, start=self.interval.lower, end=self.interval.upper, strand=strand, otherfields=None)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with new kipoiseq.extractor modules, install and so on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "vcfFile=\"/s/project/gtex-processed/vcf/GTEx_Analysis_20150112_WholeGenomeSeq_148Indiv_GATK_HaplotypeCaller.vcf.gz\"\n",
    "vcfTest=\"vcfTest\"\n",
    "! zcat /s/project/gtex-processed/vcf/GTEx_Analysis_20150112_WholeGenomeSeq_148Indiv_GATK_HaplotypeCaller.vcf.gz | head -n 300 >test.vcf\n",
    "#add \"chr\" to each line beginning with a number ( is annotated without \"chr\", only number..)\n",
    "!sed 's/^\\([0-9]\\{1,2\\}\\t\\)/chr\\1/' -i test.vcf # NO \\t in replacement for some reason, seems to be there anyway\n",
    "!bgzip -c test.vcf > test.vcf.gz\n",
    "#create index\n",
    "!tabix -p vcf test.vcf.gz  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only usable with index!\n",
    "(base) [reinharj@ouga04 bazenji]$ bgzip -c vcfTest > test.vcf.gz\n",
    "(base) [reinharj@ouga04 bazenji]$ tabix -p vcf test.vcf.gz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kipoiseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kipoiseq.extractors' from '/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages/kipoiseq/extractors/__init__.py'>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(kipoiseq)\n",
    "reload(kipoiseq.extractors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c bioconda cyvcf2 -y #did this manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import cyvcf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoiseq.extractors.vcf_seq import MultiSampleVCF\n",
    "vcfReader=MultiSampleVCF(\"test.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "        from pybedtools import Interval\n",
    "        #\"1 for chr1\" in this vcf-file....\n",
    "        testInterval= Interval(\"chr1\", start=10000, end=30000, strand=\"+\", otherfields=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybedtools import Interval\n",
    "from kipoiseq.extractors.vcf_seq import MultiSampleVCF\n",
    "\n",
    "sample1=\"GTEX-QV31-0003-SM-5URDH\"\n",
    "sample2=\"GTEX-R55E-0003-SM-5URBX\"\n",
    "\n",
    "vcfReader=MultiSampleVCF(\"test.vcf.gz\")\n",
    "#\"1 for chr1\" in this vcf-file....\n",
    "testInterval= Interval(\"chr1\", start=10175, end=10179, strand=\"+\", otherfields=None) #end=10145 works, 10146 hangs -> first variant there...\n",
    "testVariant=list(vcfReader.fetch_variants(testInterval,\"GTEX-QV31-0003-SM-5URDH\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variant(chr1:10177 A/C)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [0, 0, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False],\n",
       " [-1, -1, False]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVariant.genotypes #TODO .genotype or .gt_types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2,\n",
       "       2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0,\n",
       "       2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2,\n",
       "       0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testVariant.gt_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoiseq.extractors import MultiSampleVCF\n",
    "class AllelicMultiSampleVCF(MultiSampleVCF):\n",
    "    \"\"\"supports variant-query according to genotype\n",
    "    #TODO clean up code repetition... all in one method...\n",
    "    \"\"\"\n",
    "    def _has_variant_homo(self, variant, sample_id):\n",
    "        return variant.gt_types[self.sample_mapping[sample_id]] == 2 #might have to use ==3 since 2 is \"unknown/*\" ?\n",
    "    def _has_variant_hetero(self, variant, sample_id):\n",
    "        return variant.gt_types[self.sample_mapping[sample_id]] == 1\n",
    "    \n",
    "    def fetch_variants_homo(self, interval, sample_id=None):\n",
    "        for v in self(self._region(interval)):\n",
    "            if sample_id is None or self._has_variant_homo(v, sample_id):\n",
    "                yield v\n",
    "    def fetch_variants_hetero(self, interval, sample_id=None):\n",
    "        for v in self(self._region(interval)):\n",
    "            if sample_id is None or self._has_variant_hetero(v, sample_id):\n",
    "                yield v      \n",
    "    \n",
    "\n",
    "from kipoiseq.extractors import BaseExtractor,VariantSeqExtractor\n",
    "import pdb\n",
    "class AllelicVCFSeqExtractor(BaseExtractor):\n",
    "    def __init__(self, fasta_file, vcf_file):\n",
    "        self.fasta_file = fasta_file\n",
    "        self.vcf_file = vcf_file\n",
    "        self.variant_extractor = VariantSeqExtractor(fasta_file)\n",
    "        self.vcf = AllelicMultiSampleVCF(vcf_file)\n",
    "  \n",
    "    def get_allelic_variants(self,homoVars,heteroVars):\n",
    "        \"\"\"\n",
    "        hetero-allelic variants are only used on first allele, homo- on both\n",
    "        \"\"\"\n",
    "        from itertools import chain\n",
    "        return [chain(homoVars,heteroVars),homoVars]\n",
    "        \n",
    "    def extract(self, interval, anchor=None, sample_id=None, fixed_len=True):\n",
    "        \n",
    "        print(\"getting variants...\")\n",
    "        homoVars=self.vcf.fetch_variants_homo(interval, sample_id)\n",
    "        heteroVars=self.vcf.fetch_variants_hetero(interval, sample_id)\n",
    "        \n",
    "        #remove if print not needed...\n",
    "        from itertools import tee\n",
    "        homoVars,homoVars_print=tee(homoVars)\n",
    "        heteroVars,heteroVars_print=tee(heteroVars)\n",
    "        print(\"sorting variants, homo:{}, hetero:{}...\".format(len(list(homoVars_print)),len(list(heteroVars_print))))\n",
    "\n",
    "        vars1,vars2=self.get_allelic_variants(homoVars,heteroVars)\n",
    "\n",
    "        vars1,vars1_print=tee(vars1)\n",
    "        vars2,vars2_print=tee(vars2)\n",
    "        print(\"sortED variants, 1st:{}, 2nd:{}...\".format(len(list(vars1_print)),len(list(vars2_print))))\n",
    "        print(\"getting mutated seq...\")\n",
    "        \n",
    "        allele1=self.variant_extractor.extract(\n",
    "                interval, variants=vars1,\n",
    "                anchor=anchor, fixed_len=fixed_len)        \n",
    "        allele2=self.variant_extractor.extract(\n",
    "                interval, variants=vars2,\n",
    "                anchor=anchor, fixed_len=fixed_len)\n",
    "        \n",
    "        return [allele1,allele2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting variants...\n",
      "sorting variants, homo:1, hetero:0...\n",
      "getting mutated seq...\n",
      "['aacc', 'aacc']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pybedtools import Interval\n",
    "from kipoiseq.extractors import SingleSeqVCFSeqExtractor\n",
    "sample1=\"GTEX-QV31-0003-SM-5URDH\"\n",
    "sample2=\"GTEX-R55E-0003-SM-5URBX\"\n",
    "#\"1 for chr1\" in this vcf-file....\n",
    "testInterval= Interval(\"chr1\", start=10175, end=10179, strand=\"+\", otherfields=None) #end=10145 works, 10146 hangs -> first variant there...\n",
    "testExtractor=AllelicVCFSeqExtractor('/s/genomes/human/hg38/hg38.fa',\"/data/ouga/home/ag_gagneur/reinharj/REP/rep/notebooks/bazenji/test.vcf.gz\")\n",
    "testOut=testExtractor.extract(testInterval,10143,sample2)\n",
    "print(testOut)\n",
    "testOut[0]==testOut[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accctaaCctCTccc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pybedtools import Interval\n",
    "from kipoiseq.extractors import SingleSeqVCFSeqExtractor\n",
    "sample1=\"GTEX-QV31-0003-SM-5URDH\" #homo-neg at first snp (1_10146_AC_A_b37) \n",
    "sample2=\"GTEX-R55E-0003-SM-5URBX\" #hetero at first snp (1:10146)\n",
    "sample5=\"GTEX-N7MS-0009-SM-5JK3E\" #homo-neg for snp at 1_10177_A_C_b37 (sample 1/2 homo-unknown there)\n",
    "sample23=\"GTEX-OXRK-0004-SM-5JK32\" #homo-pos for 1_10327_T_C_b37\n",
    "#\"1 for chr1\" in this vcf-file....\n",
    "testInterval= Interval(\"chr1\", start=10170, end=10185, strand=\"+\", otherfields=None) #end=10145 works, 10146 hangs -> first variant there...\n",
    "testExtractor=SingleSeqVCFSeqExtractor('/s/genomes/human/hg38/hg38.fa',\"/data/ouga/home/ag_gagneur/reinharj/REP/rep/notebooks/bazenji/test.vcf.gz\")\n",
    "testOut=testExtractor.extract(testInterval,10175,sample2)\n",
    "print(testOut)\n",
    "testOut[0]==testOut[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing pyvcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t10230\t1_10230_AC_A_b37\tAC\tA\t97.75\tLCR\tAC=1;AF=0.003704;AN=270;BaseQRankSum=0.747;CCC=2596;ClippingRankSum=-0.747;DP=9628;FS=0;GQ_MEAN=10.21;GQ_STDDEV=15.23;HWP=0.0046;InbreedingCoeff=-0.1778;MQ=31.9;MQ0=0;MQRankSum=0.747;NCC=232;NEGATIVE_TRAIN_SITE;QD=6.98;ReadPosRankSum=-0.747;VQSLOD=0.412;culprit=FS\tGT:AD:DP:GQ:PL\t0/0:96,0:96:0:0,0,777\t./.:64,0:64:.:.\t0/0:91,0:91:0:0,0,401\t0/0:88,0:88:0:0,0,640\t0/0:21,0:21:0:0,0,45\t0/0:2,0:2:6:0,6,55\t0/0:22,0:22:0:0,0,431\t0/0:21,0:21:0:0,0,95\t0/0:48,0:48:0:0,0,54\t0/0:60,0:60:0:0,0,1314\t./.:12,0:12:.:.\t0/0:48,0:48:0:0,0,468\t0/0:28,0:28:0:0,0,215\t0/0:23,0:23:30:0,30,450\t./.:25,0:25:.:.\t0/0:51,0:51:40:0,40,1392\t0/0:66,0:66:0:0,0,708\t0/0:27,0:27:0:0,0,317\t0/0:64,0:64:0:0,0,434\t0/0:40,0:40:0:0,0,478\t0/0:65,0:65:0:0,0,1102\t0/0:22,0:22:14:0,14,574\t0/0:39,0:39:0:0,0,908\t0/0:23,0:23:0:0,0,194\t0/0:34,0:34:8:0,8,783\t0/0:19,0:19:0:0,0,325\t0/0:38,0:38:0:0,0,601\t0/0:64,0:64:0:0,0,735\t0/0:61,0:61:0:0,0,570\t0/0:48,0:48:0:0,0,827\t0/0:53,0:53:0:0,0,332\t0/0:35,0:35:0:0,0,383\t0/0:14,0:14:0:0,0,216\t0/0:16,0:16:12:0,12,414\t0/0:36,0:36:10:0,10,1002\t0/0:11,0:11:0:0,0,45\t0/0:11,0:11:0:0,0,179\t0/0:43,0:43:0:0,0,533\t0/0:83,0:83:0:0,0,1004\t0/0:9,0:9:0:0,0,45\t0/0:99,0:99:0:0,0,905\t0/0:17,0:17:0:0,0,313\t0/0:40,0:40:0:0,0,407\t0/0:63,0:63:0:0,0,63\t0/0:69,0:69:0:0,0,439\t0/0:26,0:26:12:0,12,180\t0/0:47,0:47:0:0,0,497\t0/0:14,0:14:0:0,0,299\t./.:1,0:1:.:.\t0/0:19,0:19:0:0,0,234\t0/0:79,0:79:0:0,0,687\t0/0:107,0:107:0:0,0,303\t0/0:101,0:101:0:0,0,844\t0/0:103,0:103:0:0,0,320\t0/0:75,0:75:0:0,0,754\t0/0:79,0:79:0:0,0,646\t0/0:119,0:119:0:0,0,492\t0/0:91,0:91:0:0,0,1353\t0/0:95,0:95:0:0,0,198\t0/0:70,0:70:0:0,0,633\t0/0:88,0:88:0:0,0,586\t0/0:85,0:85:0:0,0,304\t0/0:94,0:94:0:0,0,217\t0/0:79,0:79:0:0,0,736\t0/1:5,0:5:17:17,0,26\t0/0:53,0:53:0:0,0,701\t0/0:90,0:90:0:0,0,930\t0/0:40,0:40:0:0,0,141\t0/0:64,0:64:0:0,0,562\t0/0:13,0:13:0:0,0,45\t0/0:30,0:30:0:0,0,500\t./.:18,0:18:.:.\t./.:76,0:76:.:.\t./.:18,0:18:.:.\t0/0:60,0:60:0:0,0,757\t0/0:56,0:56:0:0,0,285\t0/0:76,0:76:0:0,0,272\t./.:10,0:10:.:.\t0/0:56,0:56:0:0,0,117\t0/0:73,0:73:0:0,0,357\t0/0:28,0:28:37:0,37,630\t0/0:43,0:43:0:0,0,87\t0/0:71,0:71:0:0,0,430\t0/0:81,0:81:0:0,0,1015\t0/0:90,0:90:0:0,0,710\t0/0:120,0:120:0:0,0,727\t0/0:120,0:120:0:0,0,538\t0/0:116,0:116:0:0,0,1351\t0/0:103,0:103:0:0,0,502\t0/0:83,0:83:0:0,0,135\t./.:100,0:100:.:.\t0/0:45,0:45:0:0,0,509\t0/0:90,0:90:0:0,0,551\t0/0:73,0:73:0:0,0,148\t0/0:65,0:65:0:0,0,725\t0/0:73,0:73:0:0,0,795\t0/0:88,0:88:0:0,0,889\t0/0:99,0:99:0:0,0,616\t0/0:96,0:96:0:0,0,317\t0/0:90,0:90:0:0,0,860\t./.:62,0:62:.:.\t0/0:82,0:82:0:0,0,341\t0/0:84,0:84:0:0,0,1009\t0/0:99,0:99:0:0,0,736\t0/0:92,0:92:0:0,0,523\t0/0:88,0:88:0:0,0,611\t0/0:48,0:48:0:0,0,313\t0/0:91,0:91:0:0,0,651\t0/0:158,0:158:0:0,0,892\t0/0:85,0:85:0:0,0,620\t0/0:78,0:78:0:0,0,700\t0/0:74,0:74:0:0,0,640\t0/0:66,0:66:0:0,0,217\t0/0:50,0:50:0:0,0,520\t0/0:59,0:59:0:0,0,484\t0/0:112,0:112:0:0,0,105\t0/0:84,0:84:0:0,0,794\t0/0:69,0:69:0:0,0,179\t0/0:63,0:63:0:0,0,375\t0/0:179,0:179:0:0,0,1173\t0/0:72,0:72:0:0,0,803\t./.:42,0:42:.:.\t0/0:12,0:12:0:0,0,231\t0/0:90,0:90:0:0,0,679\t0/0:94,0:94:0:0,0,216\t0/0:91,0:91:0:0,0,919\t0/0:94,0:94:0:0,0,657\t./.:71,0:71:.:.\t0/0:86,0:86:0:0,0,172\t0/0:80,0:80:0:0,0,971\t0/0:77,0:77:0:0,0,543\t0/0:79,0:79:0:0,0,651\t0/0:118,0:118:0:0,0,695\t./.:83,0:83:.:.\t0/0:73,0:73:0:0,0,541\t0/0:109,0:109:0:0,0,193\t0/0:96,0:96:0:0,0,812\t0/0:174,0:174:0:0,0,806\t0/0:69,0:69:0:0,0,271\t0/0:97,0:97:0:0,0,766\t0/0:109,0:109:0:0,0,1302\t0/0:78,0:78:0:0,0,901\t0/0:83,0:83:0:0,0,913\t0/0:49,0:49:0:0,0,1003\t0/0:63,0:63:0:0,0,562\t0/0:37,0:37:0:0,0,251\t0/0:37,0:37:0:0,0,319\t0/0:49,0:49:0:0,0,512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pybedtools import Interval\n",
    "import cyvcf2\n",
    "testVCF=cyvcf2.VCF(\"/data/ouga/home/ag_gagneur/reinharj/REP/rep/notebooks/bazenji/test.vcf.gz\")\n",
    "#testInterval= Interval(\"chr1\", start=10140, end=10146, strand=\"+\", otherfields=None) #end=10145 works, 10146 hangs -> first variant there...\n",
    "testVariantGen=testVCF(\"chr1:10220-10233\")\n",
    "#testVariantGen=testVCF(\"chr1:2-9\") #\"official\" testfile\n",
    "\n",
    "for v in testVariantGen:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyvcf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyvcf2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output-writer with Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zarr\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/5d/95f88adf4f50947949942364e9501f0bb06d3e3159018e20c23c1d462ae8/zarr-2.2.0.tar.gz (3.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.3MB 1.3MB/s \n",
      "\u001b[?25hCollecting asciitree (from zarr)\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/6a/885bc91484e1aa8f618f6f0228d76d0e67000b0fdd6090673b777e311913/asciitree-0.3.3.tar.gz\n",
      "Requirement already satisfied: numpy>=1.7 in /data/nasif12/modules_if12/SL7/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages (from zarr) (1.16.0)\n",
      "Collecting fasteners (from zarr)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/3a/096c7ad18e102d4f219f5dd15951f9728ca5092a3385d2e8f79a7c1e1017/fasteners-0.14.1-py2.py3-none-any.whl\n",
      "Collecting numcodecs>=0.5.3 (from zarr)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/1c/b1537659c5900312f77454f3eca25c728bf1b0ab24ccbcca5e1d712a661b/numcodecs-0.6.3.tar.gz (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 1.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /data/nasif12/modules_if12/SL7/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages (from fasteners->zarr) (1.12.0)\n",
      "Collecting monotonic>=0.1 (from fasteners->zarr)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: zarr, asciitree, numcodecs\n",
      "  Running setup.py bdist_wheel for zarr ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /data/ouga/home/ag_gagneur/reinharj/.cache/pip/wheels/60/68/03/ed754a88e8af5cc9d77d6b043ac7913a69a0c4bccf036b56b2\n",
      "  Running setup.py bdist_wheel for asciitree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /data/ouga/home/ag_gagneur/reinharj/.cache/pip/wheels/1d/d9/58/9808b306744df0208fccc640d3d9952a5bc7468502d42897d5\n",
      "  Running setup.py bdist_wheel for numcodecs ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /data/ouga/home/ag_gagneur/reinharj/.cache/pip/wheels/75/ea/37/8a1c2b6e937606f90dd0a9659783790d922efd1cf98d7a82a9\n",
      "Successfully built zarr asciitree numcodecs\n",
      "Installing collected packages: asciitree, monotonic, fasteners, numcodecs, zarr\n",
      "Successfully installed asciitree-0.3.3 fasteners-0.14.1 monotonic-1.5 numcodecs-0.6.3 zarr-2.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "class ZarrVariantPredWriter(object):\n",
    "    def __init__(self,outputFile,genes,samples,cAlleles,genePositions,predSize):\n",
    "        \"\"\"set up data array, annotate with attributes\n",
    "        cAlleles and predSize are given as raw numbers/dimension size\n",
    "        genes, samples and genePositions are given as elements\n",
    "        \n",
    "        \"\"\"\n",
    "        import zarr\n",
    "        self.filename=outputFile\n",
    "        self.cGenes=len(genes)\n",
    "        self.cSamples=len(samples)\n",
    "        self.cGenePositions=len(genePositions)\n",
    "        self.cAlleles=cAlleles\n",
    "        self.cPredSize=predSize\n",
    "        #Allele got canceled, just append allele 2 to allele1\n",
    "        self.data=zarr.open(self.filename, mode='w', shape=(self.cGenes,self.cSamples,self.cAlleles,self.cGenePositions,self.cPredSize),\n",
    "                 dtype='f8') #TODO: precision right? chunksize left out for now, are there default values? \"chunks=(1000, 1000),\"\n",
    "        \n",
    "        self.data.attrs['genes'] = self.as_idx_dict(genes)\n",
    "        self.data.attrs[\"samples\"]=self.as_idx_dict(samples)\n",
    "        self.data.attrs[\"genePositions\"]=self.as_idx_dict(genePositions)\n",
    "    @staticmethod    \n",
    "    def as_idx_dict(lis):\n",
    "        \"\"\"for O1 lookup\"\"\"\n",
    "        dic={}\n",
    "        for idx,elem in enumerate(lis):\n",
    "            dic[elem]=idx\n",
    "        return dic\n",
    "        \n",
    "    def batch_write(self,annotatedPreds):\n",
    "        \"\"\"plug in predictions in right position, given by metadata and annotation-array\n",
    "\n",
    "        gene, sample and allele can differ from prediction to prediction\n",
    "        expects all locations on gene in one go\n",
    "        \"\"\"\n",
    "        \n",
    "        for inputIdx,predPerInput in enumerate(annotatedPreds[\"preds\"]):\n",
    "            geneId=annotatedPreds[\"metadata\"][\"gene_id\"][inputIdx]\n",
    "            sampleId=annotatedPreds[\"metadata\"][\"sample_id\"][inputIdx]\n",
    "            \n",
    "            alleleIdx=annotatedPreds[\"metadata\"][\"allele_id\"][inputIdx]\n",
    "            geneIdx=self.data.attrs[\"genes\"][geneId]\n",
    "            sampleIdx=self.data.attrs[\"samples\"][sampleId]\n",
    "            print(predPerInput.shape)\n",
    "            self.data[geneIdx,sampleIdx,alleleIdx]=predPerInput\n",
    "\n",
    "        return\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "test=ZarrVariantWriter(\"test\",[\"gene1\",\"gene2\",\"gene4\"],[\"samp1\",\"samp2\"],2,[0],10)\n",
    "testPreds=np.array([range(0,10),range(10,20)])\n",
    "testPredsShapedArray=np.reshape(testPreds,(2,1,10))\n",
    "testBatch={\"preds\":testPredsShapedArray,\n",
    "          \"metadata\":{\n",
    "              \"gene_id\":np.array([\"gene4\",\"gene2\"]),\n",
    "              \"sample_id\":np.array([\"samp2\",\"samp1\"]),\n",
    "              \"allele_id\":np.array([1,1])\n",
    "          }}\n",
    "test.batch_write(testBatch)\n",
    "\n",
    "#Todo: read and check..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test-tss file\n",
    "#! head -n 20 /s/project/avsec/ExPecto/resources/geneanno.csv> testTSS.csv\n",
    "tssFile=\"testTSS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data-loader tut here: https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "basenjiSeqSize=131072 \n",
    "testData = RepDataset(\"dummy\",\"dummy\",tssFile,-int(basenjiSeqSize/2),int(basenjiSeqSize/2),[\"dummySampleID\"])\n",
    "\n",
    "testBatch=testData.__getitem__(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': [array([[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.]])],\n",
       " 'metadata': {'gene_id': array(['ENSG00000001631', 'ENSG00000001631'], dtype='<U15'),\n",
       "  'sample_id': array(['dummySampleID', 'dummySampleID'], dtype='<U13'),\n",
       "  'allele_id': array([0, 1])}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000000003', 'ENSG00000000003', 'ENSG00000000005',\n",
      "       'ENSG00000000005', 'ENSG00000000419', 'ENSG00000000419'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000000457', 'ENSG00000000457', 'ENSG00000000460',\n",
      "       'ENSG00000000460', 'ENSG00000000938', 'ENSG00000000938'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000000971', 'ENSG00000000971', 'ENSG00000001036',\n",
      "       'ENSG00000001036', 'ENSG00000001084', 'ENSG00000001084'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000001167', 'ENSG00000001167', 'ENSG00000001460',\n",
      "       'ENSG00000001460', 'ENSG00000001461', 'ENSG00000001461'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000001497', 'ENSG00000001497', 'ENSG00000001561',\n",
      "       'ENSG00000001561', 'ENSG00000001617', 'ENSG00000001617'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000001626', 'ENSG00000001626', 'ENSG00000001629',\n",
      "       'ENSG00000001629', 'ENSG00000001630', 'ENSG00000001630'],\n",
      "      dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID', 'dummySampleID', 'dummySampleID',\n",
      "       'dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1, 0, 1, 0, 1])}}\n",
      "{'input': [array([[1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0.]]), array([[0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0.]])], 'metadata': {'gene_id': array(['ENSG00000001631', 'ENSG00000001631'], dtype='<U15'), 'sample_id': array(['dummySampleID', 'dummySampleID'], dtype='<U13'), 'allele_id': array([0, 1])}}\n"
     ]
    }
   ],
   "source": [
    "##MAIN routine!\n",
    "\n",
    "from torch.utils import data\n",
    "from kipoi.data_utils import numpy_collate_concat\n",
    "generator = data.DataLoader(testData,batch_size=3, collate_fn=numpy_collate_concat)\n",
    "\n",
    "import kipoi\n",
    "model = kipoi.get_model('Basenji')\n",
    "#TODO gather params below\n",
    "writer=ZarrVariantPredWriter(outfile,genes,samples,cAlleles,positionsOnGene,predictionSize)\n",
    "\n",
    "\n",
    "for batch in generator:\n",
    "    preds=model.predict_on_batch(batch['inputs'])\n",
    "    #TODO choose/compute right bin AFTER TSS, not over. For now, just use middle\n",
    "    #see https://github.com/kipoi/models/issues/87 for info n dimensions\n",
    "    posidx = int(960/2)\n",
    "    #remember: id_inputvec(batchsize,here allele1 and 2), id_genomicInterval, id_features/\"tissues\"\n",
    "    tssExpr=preds[:,pos_idx:(pos_idx+1),:]\n",
    "    batch[\"preds\"]=tssExpr\n",
    "    writer.write_batch(batch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "model = kipoi.get_model('Basenji')\n",
    "\n",
    "\n",
    "#Standard prediction process in kipoi-basenji\n",
    "# Download example dataloader kwargs\n",
    "dl_kwargs = model.default_dataloader.download_example('example')\n",
    "# Get the dataloader and instantiate it\n",
    "dl = model.default_dataloader(**dl_kwargs)\n",
    "# get a batch iterator\n",
    "it = dl.batch_iter(batch_size=2) #does not work with anything else\n",
    "# predict for a batch\n",
    "batch = next(it)\n",
    "preds=model.predict_on_batch(batch['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /data/nasif12/home_if12/reinharj/.kipoi/models/Basenji/downloaded/model_files/ckp/model.meta\n",
      "Using downloaded and verified file: /data/nasif12/home_if12/reinharj/.kipoi/models/Basenji/downloaded/model_files/ckp/model.index\n",
      "Using downloaded and verified file: /data/nasif12/home_if12/reinharj/.kipoi/models/Basenji/downloaded/model_files/ckp/model.data-00000-of-00001\n",
      "Using downloaded and verified file: /data/nasif12/home_if12/reinharj/.kipoi/models/Basenji/downloaded/model_files/const_feed_dict_pkl/3a76c37eb9ad255680ba774b110de1be\n",
      "INFO:tensorflow:Restoring parameters from /data/nasif12/home_if12/reinharj/.kipoi/models/Basenji/downloaded/model_files/ckp/model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2, 2, 4) for Tensor 'inputs:0', which has shape '(2, 131072, 4)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-8f7354449ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkipoi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkipoi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Basenji'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages/kipoi/model.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         return self.sess.run(self.target_ops,\n\u001b[0;32m-> 1514\u001b[0;31m                              feed_dict=merge_dicts(feed_dict, self.const_feed_dict))\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/modules/i12g/anaconda/3-5.0.1/envs/rep/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2, 2, 4) for Tensor 'inputs:0', which has shape '(2, 131072, 4)'"
     ]
    }
   ],
   "source": [
    "import kipoi\n",
    "model = kipoi.get_model('Basenji')\n",
    "preds=model.predict_on_batch(testBatch['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.predict_on_batch(testBatch['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape\n",
    "#TODO choose/compute right bin AFTER TSS, not over. For now, just use middle\n",
    "#see https://github.com/kipoi/models/issues/87 for info n dimensions\n",
    "tssExpr=preds[:,int(960/2),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8517308 ,  3.6696124 ,  1.8414515 , ...,  7.1143007 ,\n",
       "         4.61417   , 10.097965  ],\n",
       "       [ 0.07730692, 14.220292  ,  0.02221763, ...,  2.2907472 ,\n",
       "         0.02211935,  1.0927494 ]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tssExpr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
