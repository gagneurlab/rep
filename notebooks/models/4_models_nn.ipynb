{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "Implement a neural network model using the individual and gene effect information.\n",
    "\n",
    "### TODO \n",
    " - 1. Autoencoder for individual effect\n",
    "\n",
    "### Conclusions\n",
    " - 1. For a model with one single layer 95 or 64 nodes does not make any difference. Using Huber-loss insead of mean squared error also does not make any difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import comet_ml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.losses import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import *\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "import rep.preprocessing_new as prep\n",
    "import rep.datasets as d\n",
    "import rep.models as m\n",
    "import rep.metrics as mt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%autoreload 1\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# import keras\n",
    "# from keras import backend as K\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.layers import *\n",
    "\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.losses import *\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto( device_count = {'GPU': 1, 'CPU': 4} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18180157204057138633\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9763388653158302754\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2737033691413181194\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3254583296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8321024024303550921\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.readlink(os.path.join(\"..\",\"..\",\"data\"))\n",
    "path = os.path.join(data_path,\"processed\",\"gtex\")\n",
    "x_inputs_h5 = os.path.join(path,\"X_inputs_pc_onlyblood.h5\")\n",
    "y_targets_h5 = os.path.join(path,\"Y_targets_pc_onlyblood.h5\")\n",
    "train_raw, valid_raw = d.rep_blood_expression(x_inputs_h5, y_targets_h5, label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter train and valid by tissue\n",
    "train = train_raw.filter_by(from_tissue='Whole Blood',to_tissue='Muscle - Skeletal')\n",
    "valid = valid_raw.filter_by(from_tissue='Whole Blood',to_tissue='Muscle - Skeletal')\n",
    "del train_raw, valid_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 19932), (220, 19932), (220, 11), (19932, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.inputs.shape, train.targets.shape, train.metadata.shape, train.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive plot of the loss\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    \n",
    "#     def __init__(self,start_epoch=1):\n",
    "#         self.start_epoch = start_epoch\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "#         print(epoch)\n",
    "#         if epoch >= self.start_epoch:\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "plot_losses = PlotLosses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Autoencoder for individual effect\n",
    "The AE should perform similar to the PCA (idealy even better)<br/>\n",
    "PCA performance for the individual effect (mean_spearmanr = 0.78, median_spearmanr = 0.93 (ncomp = 95)\n",
    "\n",
    "Model 1 hidden layer with 95 nodes: mean_spearmanr = 0.77, median_spearmanr = 0.93 <br/>\n",
    "Model 1 hidden layer with 95 nodes + huber_loss: mean_spearmanr = 0.77, median_spearmanr = 0.93 <br/>\n",
    "Model 1 hidden layer with 64 nodes: mean_spearmanr = 0.77, median_spearmanr = 0.93 <br/>\n",
    "Model 1 hidden layer with 32 nodes: mean_spearmanr = 0.77, median_spearmanr = 0.92 <br/>\n",
    "\n",
    "Adding more layers / Dropout or activation function does not help improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60019a52be81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0madam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.validation import check_array as check_arrays\n",
    "\n",
    "# loss\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return K.mean(K.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def huber_loss(y_true, y_pred, clip_delta=1):\n",
    "    error = y_true - y_pred\n",
    "    cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "\n",
    "# optimizer\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0000001)\n",
    "\n",
    "# autoencoder\n",
    "code_size = 32\n",
    "ae = Sequential([   \n",
    "    Dense(128, input_shape=(train.inputs.shape[1],)),\n",
    "    Dense(code_size),\n",
    "    Dense(128),\n",
    "    Dense(train.inputs.shape[1])\n",
    "])\n",
    "ae.compile(optimizer = adam, \n",
    "           loss = 'mean_squared_error')\n",
    "#            loss = huber_loss)\n",
    "\n",
    "\n",
    "ae.fit(train.inputs,\n",
    "       train.inputs,\n",
    "       epochs=500,\n",
    "       batch_size=16,\n",
    "       validation_data=(valid.inputs, valid.inputs),\n",
    "       verbose=0,\n",
    "       callbacks=[EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10),\n",
    "                 plot_losses])\n",
    "\n",
    "recovered_data = ae.predict(valid.inputs)\n",
    "eval_ae = mt.rep_metric(valid.inputs, recovered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.7748012330096412,\n",
       " 'min': -0.32335198926422715,\n",
       " 'p10': 0.2714703348359809,\n",
       " 'p25': 0.682854766264811,\n",
       " 'median': 0.9232028716269403,\n",
       " 'p75': 0.9681769996956242,\n",
       " 'p90': 0.9802680604972868,\n",
       " 'max': 0.9939544695991687}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ae['spearmanr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neural network - implement gene expression imputation from blood to muscle tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Implement a network with one layer to predict from blood to muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.32708409937405153,\n",
       " 'min': -0.4964952687755446,\n",
       " 'p10': 0.015261935930561157,\n",
       " 'p25': 0.16836818324962177,\n",
       " 'median': 0.34903650372417216,\n",
       " 'p75': 0.49716618739487645,\n",
       " 'p90': 0.60299649450203,\n",
       " 'max': 0.8727828040531936}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = 64\n",
    "nn = Sequential([\n",
    "    Dense(hidden, input_shape=(train.inputs.shape[1],)),\n",
    "    Dense(train.inputs.shape[1])\n",
    "])\n",
    "nn.compile(optimizer = adam, \n",
    "           loss = 'mean_squared_error')\n",
    "nn.reset_states()\n",
    "nn.fit(train.inputs,\n",
    "       train.targets,\n",
    "       epochs=500,\n",
    "       batch_size=16,\n",
    "       validation_data=(valid.inputs, valid.targets),\n",
    "       verbose=0,\n",
    "       callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=5)])\n",
    "recovered_data = nn.predict(valid.inputs)\n",
    "eval_nn = mt.rep_metric(valid.targets, recovered_data)\n",
    "eval_nn['spearmanr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Add layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.inputs[:,:10000].reshape(-1,100,100)\n",
    "y_train = train.targets[:,:10000]\n",
    "x_valid = valid.inputs[:,:10000].reshape(-1,100,100)\n",
    "y_valid = valid.targets[:,:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "# optimizer\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0000001)\n",
    "\n",
    "def simple_model():\n",
    "    \n",
    "    hidden = 1024\n",
    "    hidden_2 = 256\n",
    "    hidden_3 = 64\n",
    "    hidden_4 = 32\n",
    "    \n",
    "    nn_aux = Sequential([\n",
    "        Dense(hidden, input_shape=(train.inputs.shape[1],)),\n",
    "        Dense(hidden_2),\n",
    "        Dense(hidden_3),\n",
    "        Dense(hidden_4),\n",
    "        Dense(train.inputs.shape[1])\n",
    "    ])\n",
    "    nn_aux.compile(optimizer = adam, \n",
    "               loss = 'mean_squared_error')\n",
    "\n",
    "    return nn_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = simple_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.29230391734801814,\n",
       " 'min': -0.40162066413046044,\n",
       " 'p10': -0.008554778273798682,\n",
       " 'p25': 0.12727561228072834,\n",
       " 'median': 0.30400512187068746,\n",
       " 'p75': 0.457812926409061,\n",
       " 'p90': 0.5804582380302498,\n",
       " 'max': 0.861583996353003}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.reset_states()\n",
    "nn.fit(train.inputs,\n",
    "       train.targets,\n",
    "       epochs=500,\n",
    "       batch_size=16,\n",
    "       validation_data=(valid.inputs, valid.targets),\n",
    "       verbose=0,\n",
    "       callbacks=[EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=5)])\n",
    "recovered_data = nn.predict(valid.inputs)\n",
    "eval_nn = mt.rep_metric(valid.targets, recovered_data)\n",
    "eval_nn['spearmanr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save(\"simple_layer_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Network \n",
    "- contains the AE hidden layer of the individual variation as first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "hidden = 128\n",
    "hidden_2 = 64\n",
    "hidden_3 = 32\n",
    "\n",
    "x = torch.tensor(train.inputs)\n",
    "y = torch.tensor(train.targets)\n",
    "model = nn.Sequential(\n",
    "                    nn.Linear(train.inputs.shape[1],hidden),\n",
    "                    nn.Conv1d(hidden,1,3,stride=1),\n",
    "                    nn.Conv1d(10,10,3,stride=2,dilation=2),\n",
    "                    nn.Conv1d(10,10,3,stride=4,dilation=4)\n",
    "#     ,\n",
    "#                     Flatten(),\n",
    "#                     nn.Linear(hidden, train.inputs.shape[1])\n",
    "                    )\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.0000001)\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    # Forward Propagation\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch: ', epoch,' loss: ', loss.item())\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "x_valid = torch.tensor(valid.inputs)\n",
    "y_valid = torch.tensor(valid.targets)\n",
    "\n",
    "y_pred = model(x_valid)\n",
    "eval_nn = mt.rep_metric(valid.targets, y_pred.detach().numpy())\n",
    "eval_nn['spearmanr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 19932)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train.inputs[:,:18000].reshape(-1,200,90)\n",
    "# y_train = train.targets[:,:18000]\n",
    "# x_valid = valid.inputs[:,:18000].reshape(-1,200,90)\n",
    "# y_valid = valid.targets[:,:18000]\n",
    "\n",
    "x_train = train.inputs[:,:18000].reshape(-1,200,90)\n",
    "y_train = train.targets\n",
    "x_valid = valid.inputs[:,:18000].reshape(-1,200,90)\n",
    "y_valid = valid.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.00000001)\n",
    "\n",
    "def model_conv(input_size1, input_size2):\n",
    "    \n",
    "    \n",
    "    # first submodel\n",
    "    input1 = keras.layers.Input(shape=(input_size1[0],input_size1[1],1))\n",
    "        \n",
    "    hidden3 = keras.layers.Conv2D(7, (3,3), strides=1, padding='valid')(input1)\n",
    "    hidden3 = keras.layers.Conv2D(7, (3,3), dilation_rate = 2, padding='valid')(hidden3)\n",
    "#     hidden3 = keras.layers.Conv2D(7, (3,3), dilation_rate = 4, padding='valid')(hidden3)\n",
    "\n",
    "    flat = keras.layers.Flatten()(hidden3)\n",
    "    \n",
    "    outh = keras.layers.Dropout(rate=0.2)(flat)\n",
    "    outh = keras.layers.Dense(32)(outh)\n",
    "       \n",
    "    outh = keras.layers.Dropout(rate=0.2)(outh)\n",
    "    outh = keras.layers.Dense(64)(outh)\n",
    "   \n",
    "    outh = keras.layers.Dropout(rate=0.2)(outh)\n",
    "    outh1 = keras.layers.Dense(128)(outh)\n",
    "\n",
    "#     outh1 = keras.layers.Dropout(0.2)(outh)\n",
    "    \n",
    "#     outh1 = keras.layers.Dense(input_size[0]*input_size[1])(outh)\n",
    "    \n",
    "#     nn_aux = keras.models.Model(inputs=input1, outputs=outh)\n",
    "#     nn_aux.compile(optimizer = adam, \n",
    "#                loss = 'mean_squared_error')\n",
    "\n",
    "    \n",
    "    # second submodel\n",
    "    input2 = keras.layers.Input(shape=(input_size2,))\n",
    "    print(input2.shape)\n",
    "    outh2 = keras.layers.Dense(64)(input2)\n",
    "    outh2 = keras.layers.Dropout(rate=0.25)(outh2)\n",
    "    outh2 = keras.layers.Dense(32)(outh2)\n",
    "    outh2 = keras.layers.Dropout(rate=0.25)(outh2)\n",
    "\n",
    "\n",
    "    print(outh2.shape)\n",
    "#     outh1 = keras.layers.Reshape(target_shape=(1,128))(outh1)\n",
    "#     outh2 = keras.layers.Reshape(target_shape=(1,32))(outh2)\n",
    "#     concat = keras.layers.concatenate([outh1, outh2])\n",
    "#     print(concat.shape)\n",
    "#     concat = K.squeeze(concat,axis=1)\n",
    "#     print(concat.shape)\n",
    "#     outh3 = keras.layers.Dense(input_size[0]*input_size[1])(concat)\n",
    "#     print(outh3.shape)\n",
    "#     print(input1.shape)\n",
    "#     print(input2.shape)\n",
    "#     print(outh3.shape)\n",
    "    outh3 = keras.layers.Dense(input_size2)(outh2)\n",
    "    print(outh3.shape)\n",
    "    nn_aux = keras.models.Model(inputs=[input1,input2], outputs=[outh3])\n",
    "    nn_aux.compile(optimizer = adam, \n",
    "               loss = 'mean_squared_error')\n",
    "\n",
    "    \n",
    "    \n",
    "    return nn_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "model_conv() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-eac03a951d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m nn.fit(x=[K.expand_dims(x_train),train.inputs],\n\u001b[1;32m      4\u001b[0m        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: model_conv() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "nn = model_conv((x_train.shape[1],x_train.shape[2]), train.inputs.shape[1])\n",
    "nn.reset_states()\n",
    "nn.fit(x=[K.expand_dims(x_train),train.inputs],\n",
    "       y=y_train,\n",
    "       epochs=500,\n",
    "#        batch_size=16,\n",
    "       steps_per_epoch=16,\n",
    "       validation_steps=1,\n",
    "       validation_data=([K.expand_dims(x_valid),valid.inputs], y_valid),\n",
    "       verbose=0,\n",
    "       callbacks=[\n",
    "           EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10)\n",
    "           , \n",
    "           plot_losses\n",
    "       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.3637025457788201,\n",
       " 'min': -0.4228279308306054,\n",
       " 'p10': 0.06465575036333858,\n",
       " 'p25': 0.223556140680859,\n",
       " 'median': 0.3907617708395499,\n",
       " 'p75': 0.5231454270948735,\n",
       " 'p90': 0.6130932639561851,\n",
       " 'max': 0.8423455572579237}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn.predict([K.expand_dims(x_valid),valid.inputs],steps=1)\n",
    "eval_nn = mt.rep_metric(y_valid, y_pred)\n",
    "eval_nn['spearmanr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0000001)\n",
    "\n",
    "def model_conv(input_size_):\n",
    "    \n",
    "#     code_size = 64\n",
    "#     inputLength = 64\n",
    "#     baseNetwork = Sequential()\n",
    "# #     baseNetwork.add(Dense(code_size))\n",
    "#     baseNetwork.add(Embedding(input_dim=100, output_dim=80, input_length=input_size_))\n",
    "#     baseNetwork.add(Conv1D(10, 20, strides=1, padding='valid'))\n",
    "#     baseNetwork.add(LeakyReLU(0.5))\n",
    "#     baseNetwork.add(Dropout(0.1))\n",
    "\n",
    "#     baseNetwork.add(Conv1D(10, 20, dilation_rate=2, padding='valid'))\n",
    "#     baseNetwork.add(LeakyReLU(0.5))\n",
    "#     baseNetwork.add(Dropout(0.1))\n",
    "\n",
    "#     baseNetwork.add(Conv1D(10, 20, dilation_rate=4, padding='valid'))\n",
    "#     baseNetwork.add(LeakyReLU(0.5))\n",
    "#     baseNetwork.add(Dropout(0.1))\n",
    "\n",
    "#     baseNetwork.add(Flatten())\n",
    "\n",
    "#     baseNetwork.add(Dense(128))\n",
    "# #     baseNetwork.add(Dropout(0.1))\n",
    "#     baseNetwork.add(Dense(code_size))\n",
    "#     baseNetwork.add(Dense(code_size))\n",
    "# #     baseNetwork.add(Dropout(0.1))\n",
    "#     baseNetwork.add(Dense(32))\n",
    "#     baseNetwork.add(Dropout(0.1))\n",
    "# #     baseNetwork.add(Dense(16))\n",
    "# #     baseNetwork.add(Dense(16))\n",
    "# #     baseNetwork.add(Dropout(0.1))\n",
    "#     baseNetwork.add(Dense(input_size_))\n",
    "\n",
    "    \n",
    "    input1 = keras.layers.Input(shape=(input_size_,))\n",
    "#     emb = keras.layers.Embedding(100, 10, input_length=input_size_)(input1)\n",
    "#     h = keras.layers.Conv1D(2, 5, strides=1, padding='valid')(emb)\n",
    "#     h = keras.layers.AveragePooling1D()(h)\n",
    "#     h = keras.layers.Conv1D(2, 5, dilation_rate=2, padding='valid')(h)\n",
    "#     h = keras.layers.AveragePooling1D()(h)\n",
    "#     h = keras.layers.Conv1D(2, 5, dilation_rate=4, padding='valid')(h)\n",
    "# #     h = keras.layers.AveragePooling1D()(h)\n",
    "#     h = keras.layers.Conv1D(2, 5, dilation_rate=16, padding='valid')(h)\n",
    "#     h = keras.layers.AveragePooling1D()(h)\n",
    "#     h = keras.layers.Conv1D(3, 5, dilation_rate=32, padding='valid')(h)\n",
    "#     h0 = keras.layers.AveragePooling1D()(h)\n",
    "#     flat = keras.layers.Flatten()(h)\n",
    "    \n",
    "#     h1 = keras.layers.Dense(128, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.005))(input1)\n",
    "#     h2 = keras.layers.Dense(64, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.005))(h1)\n",
    "#     h3 = keras.layers.Dense(32, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.005))(h2)\n",
    "#     h4 = keras.layers.Dense(64, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.005))(h3)    \n",
    "#     h5 = keras.layers.Dense(128, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.005))(h4)\n",
    "    \n",
    "    \n",
    "    h1 = keras.layers.Dense(128)(input1)\n",
    "    h = keras.layers.Dense(64)(h1)\n",
    "    h = keras.layers.Dense(32)(h)\n",
    "    h = keras.layers.Dense(64)(h)    \n",
    "    h5 = keras.layers.Dense(128)(h)    \n",
    "    h6 =  Add()([h5, h1])\n",
    "    out1 = Dropout(0.1)(h5)\n",
    "    \n",
    "    \n",
    "#     h1 = keras.layers.Dense(64)(input1)\n",
    "#     h = keras.layers.Dense(32)(h1)\n",
    "#     h = keras.layers.Dense(64)(h)\n",
    "#     out1 = Dropout(0.1)(h)\n",
    "    out2 = keras.layers.Dense(input_size_)(out1)\n",
    "    \n",
    "    baseNetwork = keras.models.Model(inputs=[input1], outputs=[out2])\n",
    "    baseNetwork.compile(optimizer = adam, \n",
    "               loss = 'mean_squared_error')\n",
    "   \n",
    "    \n",
    "    return baseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.37620974505042015,\n",
       " 'min': -0.3169373663369354,\n",
       " 'p10': 0.11251903196238353,\n",
       " 'p25': 0.26479012876865093,\n",
       " 'median': 0.40086378809487655,\n",
       " 'p75': 0.5109626566750083,\n",
       " 'p90': 0.595165725593771,\n",
       " 'max': 0.8369298264488343}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = model_conv(train.inputs[:,:10000].shape[1])\n",
    "nn.reset_states()\n",
    "nn.fit(train.inputs[:,:10000],\n",
    "       train.targets[:,:10000],\n",
    "       epochs=500,\n",
    "       batch_size=16,\n",
    "#        steps_per_epoch=16,\n",
    "#        validation_steps=1,\n",
    "       validation_data=(valid.inputs[:,:10000], valid.targets[:,:10000]),\n",
    "       verbose=0,\n",
    "       callbacks=[\n",
    "           EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10), \n",
    "           plot_losses\n",
    "       ])\n",
    "y_pred = nn.predict(valid.inputs[:,:10000])\n",
    "eval_nn = mt.rep_metric(valid.targets[:,:10000], y_pred)\n",
    "eval_nn['spearmanr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden = 256\n",
    "# hidden_2 = 128\n",
    "# hidden_3 = 32\n",
    "# hidden_4 = 16\n",
    "# # hidden_2 = 1024\n",
    "# nn = Sequential([\n",
    "#     Dense(code_size, input_shape=(train.inputs.shape[1],), trainable=False),\n",
    "#     Dense(hidden_2),\n",
    "#     Dense(hidden_3),\n",
    "#     Dense(hidden_4),\n",
    "#     Dense(train.inputs.shape[1])\n",
    "# ])\n",
    "    \n",
    "    \n",
    "#     Dropout(0.1),\n",
    "#     Dense(hidden_2),\n",
    "#     Dropout(0.1),\n",
    "#     Conv1D(filters=16, kernel_size=(3), activation='relu', input_shape=(hidden_2,1)),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Flatten(),\n",
    "#     Dense(train.inputs.shape[1])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolution1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "1D convolution layer (e.g. temporal convolution).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input over a single spatial (or temporal) dimension\n",
       "to produce a tensor of outputs.\n",
       "If `use_bias` is True, a bias vector is created and added to the outputs.\n",
       "Finally, if `activation` is not `None`,\n",
       "it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide an `input_shape` argument\n",
       "(tuple of integers or `None`, e.g.\n",
       "`(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n",
       "or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n",
       "\n",
       "# Arguments\n",
       "    filters: Integer, the dimensionality of the output space\n",
       "        (i.e. the number of output filters in the convolution).\n",
       "    kernel_size: An integer or tuple/list of a single integer,\n",
       "        specifying the length of the 1D convolution window.\n",
       "    strides: An integer or tuple/list of a single integer,\n",
       "        specifying the stride length of the convolution.\n",
       "        Specifying any stride value != 1 is incompatible with specifying\n",
       "        any `dilation_rate` value != 1.\n",
       "    padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n",
       "        `\"valid\"` means \"no padding\".\n",
       "        `\"same\"` results in padding the input such that\n",
       "        the output has the same length as the original input.\n",
       "        `\"causal\"` results in causal (dilated) convolutions,\n",
       "        e.g. `output[t]` does not depend on `input[t + 1:]`.\n",
       "        A zero padding is used such that\n",
       "        the output has the same length as the original input.\n",
       "        Useful when modeling temporal data where the model\n",
       "        should not violate the temporal order. See\n",
       "        [WaveNet: A Generative Model for Raw Audio, section 2.1]\n",
       "        (https://arxiv.org/abs/1609.03499).\n",
       "    data_format: A string,\n",
       "        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n",
       "        The ordering of the dimensions in the inputs.\n",
       "        `\"channels_last\"` corresponds to inputs with shape\n",
       "        `(batch, steps, channels)`\n",
       "        (default format for temporal data in Keras)\n",
       "        while `\"channels_first\"` corresponds to inputs\n",
       "        with shape `(batch, channels, steps)`.\n",
       "    dilation_rate: an integer or tuple/list of a single integer, specifying\n",
       "        the dilation rate to use for dilated convolution.\n",
       "        Currently, specifying any `dilation_rate` value != 1 is\n",
       "        incompatible with specifying any `strides` value != 1.\n",
       "    activation: Activation function to use\n",
       "        (see [activations](../activations.md)).\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix\n",
       "        (see [initializers](../initializers.md)).\n",
       "    bias_initializer: Initializer for the bias vector\n",
       "        (see [initializers](../initializers.md)).\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    bias_regularizer: Regularizer function applied to the bias vector\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\").\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    kernel_constraint: Constraint function applied to the kernel matrix\n",
       "        (see [constraints](../constraints.md)).\n",
       "    bias_constraint: Constraint function applied to the bias vector\n",
       "        (see [constraints](../constraints.md)).\n",
       "\n",
       "# Input shape\n",
       "    3D tensor with shape: `(batch, steps, channels)`\n",
       "\n",
       "# Output shape\n",
       "    3D tensor with shape: `(batch, new_steps, filters)`\n",
       "    `steps` value might have changed due to padding or strides.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/rep/lib/python3.6/site-packages/keras/layers/convolutional.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?keras.layers.convolutional.Convolution1D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rep)",
   "language": "python",
   "name": "rep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
